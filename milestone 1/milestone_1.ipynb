{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone 1: preprocessing\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Sofija\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Sofija\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['rewire_id', 'text', 'annotator', 'label_sexist', 'label_category', 'label_vector', 'split']\n",
      "Shape: (60000, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rewire_id</th>\n",
       "      <th>text</th>\n",
       "      <th>annotator</th>\n",
       "      <th>label_sexist</th>\n",
       "      <th>label_category</th>\n",
       "      <th>label_vector</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sexism2022_english-0</td>\n",
       "      <td>[USER] I wonder what keeps that witch looking ...</td>\n",
       "      <td>17</td>\n",
       "      <td>sexist</td>\n",
       "      <td>2. derogation</td>\n",
       "      <td>2.2 aggressive and emotive attacks</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sexism2022_english-0</td>\n",
       "      <td>[USER] I wonder what keeps that witch looking ...</td>\n",
       "      <td>2</td>\n",
       "      <td>sexist</td>\n",
       "      <td>2. derogation</td>\n",
       "      <td>2.2 aggressive and emotive attacks</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sexism2022_english-0</td>\n",
       "      <td>[USER] I wonder what keeps that witch looking ...</td>\n",
       "      <td>6</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sexism2022_english-1</td>\n",
       "      <td>What do you guys think about female \"incels\"? ...</td>\n",
       "      <td>17</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sexism2022_english-1</td>\n",
       "      <td>What do you guys think about female \"incels\"? ...</td>\n",
       "      <td>15</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              rewire_id                                               text  \\\n",
       "0  sexism2022_english-0  [USER] I wonder what keeps that witch looking ...   \n",
       "1  sexism2022_english-0  [USER] I wonder what keeps that witch looking ...   \n",
       "2  sexism2022_english-0  [USER] I wonder what keeps that witch looking ...   \n",
       "3  sexism2022_english-1  What do you guys think about female \"incels\"? ...   \n",
       "4  sexism2022_english-1  What do you guys think about female \"incels\"? ...   \n",
       "\n",
       "   annotator label_sexist label_category                        label_vector  \\\n",
       "0         17       sexist  2. derogation  2.2 aggressive and emotive attacks   \n",
       "1          2       sexist  2. derogation  2.2 aggressive and emotive attacks   \n",
       "2          6   not sexist           none                                none   \n",
       "3         17   not sexist           none                                none   \n",
       "4         15   not sexist           none                                none   \n",
       "\n",
       "   split  \n",
       "0  train  \n",
       "1  train  \n",
       "2  train  \n",
       "3  train  \n",
       "4  train  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../data/edos_labelled_individual_annotations.csv')\n",
    "print(\"Columns:\", list(data.columns))\n",
    "print(\"Shape:\", data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains a more fine-grained sexism detection, but we're working only with the `label_sexist`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rewire_id</th>\n",
       "      <th>text</th>\n",
       "      <th>annotator</th>\n",
       "      <th>label_sexist</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sexism2022_english-0</td>\n",
       "      <td>[USER] I wonder what keeps that witch looking ...</td>\n",
       "      <td>17</td>\n",
       "      <td>sexist</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sexism2022_english-0</td>\n",
       "      <td>[USER] I wonder what keeps that witch looking ...</td>\n",
       "      <td>2</td>\n",
       "      <td>sexist</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sexism2022_english-0</td>\n",
       "      <td>[USER] I wonder what keeps that witch looking ...</td>\n",
       "      <td>6</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sexism2022_english-1</td>\n",
       "      <td>What do you guys think about female \"incels\"? ...</td>\n",
       "      <td>17</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sexism2022_english-1</td>\n",
       "      <td>What do you guys think about female \"incels\"? ...</td>\n",
       "      <td>15</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              rewire_id                                               text  \\\n",
       "0  sexism2022_english-0  [USER] I wonder what keeps that witch looking ...   \n",
       "1  sexism2022_english-0  [USER] I wonder what keeps that witch looking ...   \n",
       "2  sexism2022_english-0  [USER] I wonder what keeps that witch looking ...   \n",
       "3  sexism2022_english-1  What do you guys think about female \"incels\"? ...   \n",
       "4  sexism2022_english-1  What do you guys think about female \"incels\"? ...   \n",
       "\n",
       "   annotator label_sexist  split  \n",
       "0         17       sexist  train  \n",
       "1          2       sexist  train  \n",
       "2          6   not sexist  train  \n",
       "3         17   not sexist  train  \n",
       "4         15   not sexist  train  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(columns=['label_category', 'label_vector'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are: 19 different annotators.\n",
      "Annotator IDs: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are: {len(data['annotator'].unique())} different annotators.\")\n",
    "print(\"Annotator IDs:\", sorted(data['annotator'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the 20000 unique comments was annotated by 3 different annotators. In 4444 cases, annotators reached a 2/3 agreement rather than full 3/3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are: 20000 different comments annotated in total.\n",
      "Minimum number of annotations for a comment: 3\n",
      "Maximum number of annotations for a comment: 3\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are: {len(data['rewire_id'].unique())} different comments annotated in total.\")\n",
    "print(\"Minimum number of annotations for a comment:\", data['rewire_id'].value_counts().min())\n",
    "print(\"Maximum number of annotations for a comment:\", data['rewire_id'].value_counts().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 'rewire_id' entries (comments) with 2/3 agreement among annotators: 4444\n",
      "rewire_id\n",
      "sexism2022_english-0       2\n",
      "sexism2022_english-1       1\n",
      "sexism2022_english-10      2\n",
      "sexism2022_english-100     1\n",
      "sexism2022_english-1000    1\n",
      "                          ..\n",
      "sexism2022_english-9995    1\n",
      "sexism2022_english-9996    2\n",
      "sexism2022_english-9997    1\n",
      "sexism2022_english-9998    2\n",
      "sexism2022_english-9999    2\n",
      "Name: label_sexist, Length: 20000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "unique_label_counts = data.groupby('rewire_id')['label_sexist'].nunique() # 1 (3/3 agreement) or 2 (2/3 agreement)\n",
    "agreement_2_3_count = (unique_label_counts != 1).sum() # number of comments where annotators have 2/3 agreement\n",
    "\n",
    "print(\"Number of 'rewire_id' entries (comments) with 2/3 agreement among annotators:\", agreement_2_3_count)\n",
    "print(unique_label_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['rewire_id', 'text', 'label_sexist', 'split']\n",
      "Shape: (20000, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rewire_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label_sexist</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sexism2022_english-9609</td>\n",
       "      <td>In Nigeria, if you rape a woman, the men rape ...</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sexism2022_english-16993</td>\n",
       "      <td>Then, she's a keeper. üòâ</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sexism2022_english-13149</td>\n",
       "      <td>This is like the Metallica video where the poo...</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sexism2022_english-13021</td>\n",
       "      <td>woman?</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sexism2022_english-966</td>\n",
       "      <td>I bet she wished she had a gun</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>sexism2022_english-5228</td>\n",
       "      <td>girls really get fucked almost every weekend ?</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>sexism2022_english-10140</td>\n",
       "      <td>The hatred for moslems are Reasonable and Just...</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>sexism2022_english-9726</td>\n",
       "      <td>Now this is a woman who gets it. üëÜ</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>sexism2022_english-13365</td>\n",
       "      <td>‚ÄúAmerican Idol‚Äù finalist [USER] said nothing i...</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>sexism2022_english-3523</td>\n",
       "      <td>this bi--th should be stoped she's the rapist</td>\n",
       "      <td>sexist</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      rewire_id  \\\n",
       "0       sexism2022_english-9609   \n",
       "1      sexism2022_english-16993   \n",
       "2      sexism2022_english-13149   \n",
       "3      sexism2022_english-13021   \n",
       "4        sexism2022_english-966   \n",
       "...                         ...   \n",
       "19995   sexism2022_english-5228   \n",
       "19996  sexism2022_english-10140   \n",
       "19997   sexism2022_english-9726   \n",
       "19998  sexism2022_english-13365   \n",
       "19999   sexism2022_english-3523   \n",
       "\n",
       "                                                    text label_sexist  split  \n",
       "0      In Nigeria, if you rape a woman, the men rape ...   not sexist    dev  \n",
       "1                                Then, she's a keeper. üòâ   not sexist  train  \n",
       "2      This is like the Metallica video where the poo...   not sexist  train  \n",
       "3                                                 woman?   not sexist  train  \n",
       "4                         I bet she wished she had a gun   not sexist    dev  \n",
       "...                                                  ...          ...    ...  \n",
       "19995     girls really get fucked almost every weekend ?   not sexist  train  \n",
       "19996  The hatred for moslems are Reasonable and Just...   not sexist  train  \n",
       "19997                 Now this is a woman who gets it. üëÜ   not sexist  train  \n",
       "19998  ‚ÄúAmerican Idol‚Äù finalist [USER] said nothing i...   not sexist  train  \n",
       "19999      this bi--th should be stoped she's the rapist       sexist   test  \n",
       "\n",
       "[20000 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_agg = pd.read_csv('../data/edos_labelled_aggregated.csv')\n",
    "data_agg = data_agg.drop(columns=['label_category', 'label_vector'])\n",
    "print(\"Columns:\", list(data_agg.columns))\n",
    "print(\"Shape:\", data_agg.shape)\n",
    "data_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusions drawn using regular expressions:\n",
    "\n",
    "- `[URL]`, `[USER]` are placeholders used by dataset authors instead of actual URLs and real usernames\n",
    "- female related nouns and pronouns are more frequent than male\n",
    "- hashtags `#` often used\n",
    "- huge amount of profanities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_patterns(pattern, data):\n",
    "    return Counter(match for text in data.text for match in re.findall(pattern, text)).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('[URL]', 2478), ('[USER]', 1355), ('[K]', 1), ('[DJT]', 1)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_patterns(r'\\[[A-Z]+\\]', data_agg) # catching: [USER], [URL]\n",
    "# count_patterns(r'\\b(she|her|wom[ae]n|female|girl|lady)\\b', data_agg) # female related nouns, pronouns etc.\n",
    "# count_patterns(r'\\b(he|him|his|m[ae]n|male|boy|guy|dude)\\b', data_agg) # male related nouns, pronouns etc.\n",
    "# count_patterns(r'#\\w+', data_agg) # hashtag\n",
    "# count_patterns(r'\\b(fuck|shit|damn|asshole|bitch|slut)\\b', data_agg) # profanities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text normalization\n",
    "\n",
    "What are the most common words in our concatenated text?\n",
    "\n",
    "Examining the list of the most frequent words after tokenization and punctuation removal (`[]` were also highly frequent), we found that, alongside expected stopwords (`a`, `the` etc.), there is notable frequency of female-related nouns/pronouns (`her`, `she`, `women`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words found after tokenization and punctuation removal: 470476\n",
      "Top 20 most common words: [('the', 12658), ('a', 11891), ('to', 11636), ('I', 8603), ('and', 8579), ('you', 6842), ('is', 6714), ('of', 6547), ('her', 5799), ('that', 5306), ('she', 4908), ('in', 4742), ('it', 4509), ('women', 4146), (\"n't\", 3965), ('for', 3918), ('are', 3710), ('with', 3373), ('be', 3029), ('on', 3011)]\n"
     ]
    }
   ],
   "source": [
    "words = [word for text in data_agg['text'] for word in nltk.word_tokenize(text)]\n",
    "words = [word for word in words if re.match(r'\\w', word)] # exclude punctuation\n",
    "print(\"Total number of words found after tokenization and punctuation removal:\", len(words))\n",
    "print(\"Top 20 most common words:\", Counter(words).most_common(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of curiosity, let‚Äôs find the context surrounding the first few occurrences of some specific token of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['e begins to hit the wall and some hotter, younger women enters the picture, it‚Äôs time for impulse control',\n",
       " 'eed to stop referring to all men as kings and all women as queens, this shit is getting out of hand.',\n",
       " ' like 90% of people i know IRL it just so happens women are disgusted by me-and i dont even do it IRL ?',\n",
       " \"or Assault and based on his claim that he's raped women, he should be investigated. His bragging could be\",\n",
       " 'Yes, normal women want to be dominated. Social scientists call it f',\n",
       " 'cientists call it female hypergamy. And it is why women make bad bosses for men, generally speaking.',\n",
       " ' you have few options. You drop a few points with women doing that. A guy with options doesn‚Äôt give a shi',\n",
       " 'The she-god mentality of women is going down the drain. Men make the world work ',\n",
       " \"nt pussy. Sexbots will be realistic very soon and women's days of pussy rule will be over. &#x200B;\",\n",
       " ' Europe (France, Germany etc.) is easier and that women do approach men. Here they never approach, even c']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_contexts(token, data, context_size=50, limit=10):\n",
    "    \"\"\"\n",
    "    Finds the first 'limit' occurrences of a given 'token' in dataframe 'data'\n",
    "    with a 'text' column, capturing 'context_size' characters around each occurrence.\n",
    "    Context: token position +- 'context_size' chars around.\n",
    "    \"\"\"\n",
    "    contexts = []\n",
    "\n",
    "    for text in data['text']:\n",
    "        for match in re.finditer(rf'\\b{token}\\b', text):\n",
    "            start, end = match.span()\n",
    "            # get the context around the match\n",
    "            context = text[max(0, start - context_size):min(len(text), end + context_size)] # +- context_size chars\n",
    "            contexts.append(context)\n",
    "            \n",
    "            if len(contexts) >= limit:\n",
    "                return contexts[:limit]\n",
    "\n",
    "    return contexts[:limit]\n",
    "\n",
    "find_contexts(\"women\", data_agg)\n",
    "# find_contexts(\"she\", data_agg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stopword removal\n",
    "\n",
    "`she`, `herself` should be excluded from stopwords, because we assume that those pronouns provide relevant information for our task and preserving them will be beneficial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords_set = set(stopwords.words('english'))\n",
    "stopwords_set = stopwords_set - {'she', 'she\\'s', 'herself'}\n",
    "stopwords_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After stopword filtering and analyzing the most commonly occuring words, we can observe female-related nouns/pronounces, `URL`, `USER` tokens, as well as some profanities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words found after tokenization, punctuation removal and stopword filtering: 253781\n",
      "Top 20 most common words: [('she', 6047), ('women', 4427), (\"n't\", 3982), ('url', 2480), ('like', 2424), ('get', 1713), ('woman', 1698), ('would', 1546), ('men', 1503), ('user', 1362), ('one', 1151), ('girls', 1126), ('girl', 1090), ('fuck', 1068), ('want', 995), ('think', 947), ('shit', 940), ('female', 935), ('people', 934), ('know', 924)]\n"
     ]
    }
   ],
   "source": [
    "words = [word.lower() for word in words if word.lower() not in stopwords_set]\n",
    "print(\"Total number of words found after tokenization, punctuation removal and stopword filtering:\", len(words))\n",
    "print(\"Top 20 most common words:\", Counter(words).most_common(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting in the CoNLL format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
